---
title: "Model Performance - linear"
author:
  - name: Hakan Egeli
  - name: Soumyendu Sarkar
date: 'April 24, 2018'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, echo=FALSE, include = FALSE}

# load the project. This will autoload the data and also create training and test datasets
library('ProjectTemplate')
load.project()

```

```{r, echo=FALSE, include=FALSE}

library(caret)

require(gridExtra)

```

# Explortory data analysis.

## Sales Attributes and Possible Correlations

### Correlation of Sales Summaries and Credit Limit

Since our Naive model was based on **Sales Last Year**, we wanted to see how all the sales summary variables correlated to the **Credit Limit**

```{r, echo=FALSE}
g1 <- ggplot() + 
  geom_point(aes(x = dataset$SalesLastYr, y = dataset$CreditLimit), color = 'blue') +
  xlab('Last Year\'s Sales') +
  ylab('Credit Limit') +
  scale_x_continuous(breaks=c(100000, 200000, 300000, 400000, 500000, 600000), labels=c("100K", "200K", "300K", "400K", "500K", "600K")) +
  scale_y_continuous(breaks=c(10000, 20000, 30000, 40000, 50000), labels=c("10K", "20K", "30K", "40K", "50K"))

g2 <- ggplot() + 
  geom_point(aes(x = dataset$SalesCurrentYr, y = dataset$CreditLimit), color = 'blue') +
  xlab('Current Year\'s Sales') + 
  ylab('Credit Limit') +
  scale_x_continuous(breaks=c(20000, 40000, 60000, 80000, 100000, 120000), labels=c("20K", "40K", "60K", "80K", "100K", "120K")) +
  scale_y_continuous(breaks=c(10000, 20000, 30000, 40000, 50000), labels=c("10K", "20K", "30K", "40K", "50K"))

g3 <- ggplot() + 
  geom_point(aes(x = dataset$TotalSalesLast12Mo, y = dataset$CreditLimit), color = 'blue') +
  xlab('Last 12 Mo\'s Sales') + 
  ylab('Credit Limit') +
  scale_x_continuous(breaks=c(100000, 200000, 300000, 400000, 500000, 600000), labels=c("100K", "200K", "300K", "400K", "500K", "600K")) +
  scale_y_continuous(breaks=c(10000, 20000, 30000, 40000, 50000), labels=c("10K", "20K", "30K", "40K", "50K"))

grid.arrange(g1, g2, g3, ncol=3)

```

Unfortunately, we did not see a linear correlation between any of the Sales summary variables and the Credit Limit.

### Correlation of 12 Months Sales and Major Product Category Sales

Since the major product category sales for the last 12 months make up majority of the **Last 12 Mo Sales Total** we wanted to examine which product(s) had the most significant correlation.

```{r, echo=FALSE}
g1 <- ggplot() + 
  geom_point(aes(x = dataset$PlainBandSalesLast12Mo, y = dataset$TotalSalesLast12Mo), color = 'blue') +
  xlab('Last 12 Mo\'s Plains $') +
  ylab('Last 12 Mo\'s $') +
  scale_x_continuous(limits=c(0, 100000), breaks=c(10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000), labels=c("10K", "20K", "30K", "40K", "50K", "60K", "70K", "80K", "90K", "100K")) +
  scale_y_continuous(breaks=c(100000, 200000, 300000, 400000), labels=c("100K", "200K", "300K", "400K"))

g2 <- ggplot() + 
  geom_point(aes(x = dataset$DesignBandSalesLast12Mo, y = dataset$TotalSalesLast12Mo), color = 'blue') +
  xlab('Last 12 Mo\'s Designs $') + 
  ylab('Last 12 Mo\'s $') +
  scale_x_continuous(limits=c(0, 100000), breaks=c(10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000), labels=c("10K", "20K", "30K", "40K", "50K", "60K", "70K", "80K", "90K", "100K")) +
  scale_y_continuous(breaks=c(100000, 200000, 300000, 400000), labels=c("100K", "200K", "300K", "400K"))

g3 <- ggplot() + 
  geom_point(aes(x = dataset$DiamondBandSalesLast12Mo, y = dataset$TotalSalesLast12Mo), color = 'blue') +
  xlab('Last 12 Mo\'s Diamonds $') + 
  ylab('Last 12 Mo\'s $') +
  scale_x_continuous(breaks=c(10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000), labels=c("10K", "20K", "30K", "40K", "50K", "60K", "70K", "80K", "90K", "100K")) +
  scale_y_continuous(breaks=c(100000, 200000, 300000, 400000), labels=c("100K", "200K", "300K", "400K"))

g4 <- ggplot() + 
  geom_point(aes(x = dataset$AlternativeMetalSalesLast12Mo, y = dataset$TotalSalesLast12Mo), color = 'blue') +
  xlab('Last 12 Mo\'s Alt Metal $') + 
  ylab('Last 12 Mo\'s $') +
  scale_x_continuous(breaks=c(10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000), labels=c("10K", "20K", "30K", "40K", "50K", "60K", "70K", "80K", "90K", "100K")) +
  scale_y_continuous(breaks=c(100000, 200000, 300000, 400000), labels=c("100K", "200K", "300K", "400K"))

grid.arrange(g1, g2, g3, g4, ncol=2)

```

From the scatter plots above, we can see that Plain Bands and Design Bands seem to have the strongest correlation and Diamond Bands and the Alternative Metal Bands have the least.

### Distribution of Credit Limit

We also wanted to understand how the **Credit Limits** were distributed and if the distribution was Gaussian. After plotting a histogram we realized that the Credit Limit distribution was not Gaussian. 

```{r, echo=FALSE}
ggplot() + 
  geom_histogram(aes(dataset$CreditLimit), bins = 40) +
  scale_x_continuous(breaks=c(5000, 10000, 15000, 20000, 30000, 40000, 50000), labels=c("5K", "10K", "15K", "20K", "30K", "40K", "50K")) +
  ggtitle('Distribution of Credit Limit') +
  xlab('Credit Limit') + 
  ylab('Distribution')
```

### Relationship Between Avg Days of Pay and Credit Limits

Then we wanted to examine if there was a realtionship between the **Average Days of Pay Categories** and the **Credit Limit**.

```{r, echo=FALSE}
ggplot(dataset, aes(x = AvgDaysOfPayCategory, y = CreditLimit, fill = AvgDaysOfPayCategory)) + 
  geom_boxplot(outlier.color = 'blue', outlier.shape = 1) +
  scale_y_log10() +
  stat_summary(fun.y = mean, geom = "point", shape = 1, size = 1, color = "white") +
  theme(legend.position = "") +
  ggtitle('Avg Days of Pay vs Credit Limit') +
  xlab('Avg Days of Pay') + 
  ylab('Credit Limit')
```

If we remove the Category N/A from the plot, we do see that the means (white circles) do show a possible polynomial relationship. We also wanted to see what the distribution of **Credit Limits** looked like for each of the **Average Days of Pay**.

### Distribution of Credit Limit Among Avg Days of Pay

After plotting a histogram for the Credit Limit for each of the Average Days of Pay category, we did see that the first three categories had a gaussian distribution for the Credit Limits.

```{r, echo=FALSE}

ggplot(data = dataset, aes(x = CreditLimit)) + geom_histogram(binwidth = 2000) + facet_wrap(~AvgDaysOfPayCategory)

```

## Non-Sales Attributes and Possible Correlations

We enhanced our dataset by bringing in Census data for **"Retail Trade: Geographic Area Series: Summary Statistics for the U.S., States, Metro Areas, Counties, and Places"**, **Annual Estimates of the Resident Population**, **MEDIAN INCOME IN THE PAST 12 MONTHS (IN 2016 INFLATION-ADJUSTED DOLLARS)**, **TOTAL POPULATION**, and **INDUSTRY BY MEDIAN EARNINGS IN THE PAST 12 MONTHS (IN 2016 INFLATION-ADJUSTED DOLLARS) FOR THE CIVILIAN EMPLOYED POPULATION 16 YEARS AND OVER** and mapping these values to our customer records via StateFIPS, CountyFIPS and CBSA Codes (for metro areas).

### Avg Days of Pay and Median Household Income 

We wanted to see if there was a correlation between the Average Days of Pay and Median Household Income where the stores are located and we did see that the first three categories had very similar patterns of Median Income distribution.

```{r, echo=FALSE}
ggplot(dataset, aes(x = AvgDaysOfPayCategory, y = MedianIncomeHouseholds, color = CreditLimit)) + 
  geom_jitter() +
  stat_summary(fun.y = mean, geom = "point", shape = 1, size = 2, color = "red") +
  theme(legend.position = "") +
  ggtitle('Avg Days of Pay vs Median Income Households') +
  xlab('Avg Days of Pay') + 
  ylab('Median Income Households')
```

And finally we wanted to examine if there was any kind of correlation between the 12 Mos Sales and the **Urban Influence**, which is an indicator whether the statistical area is a Major Metro Area, Micro Metro Area, Micro Metro Adjesent to a Major Metro Area, or more Rural. Additionally, we have examined the correlation between the **Total Population** and the **Number of Jewelry Stores** (via the NAICS Code 4483 - Jewelry Stores) associated with that customer's location.

```{r, echo=FALSE}
g1 <- ggplot(dataset, aes(x = factor(UrbanInfluenceCode), y = dataset$TotalSalesLast12Mo, color = MetroIndicator)) + 
  geom_jitter() +
  scale_y_continuous(breaks=c(100000, 200000, 300000, 400000), labels=c("100K", "200K", "300K", "400K")) +
  stat_summary(fun.y = mean, geom = "point", shape = 1, size = 1, color = "white") +
  theme(legend.position = "") +
  ggtitle('12 Mo Sales Over Urban Influence') +
  xlab('Urban Influence Code') + 
  ylab('Total $ Last 12 Mo')

g2 <- ggplot() + 
  geom_point(aes(x = dataset$TotalPopulation, y = dataset$NumberOfJewelryStores), color = 'blue') +
  scale_x_continuous(breaks=c(5000000, 10000000, 15000000, 20000000), labels=c("5M", "10M", "15M", "20M")) +
  scale_y_continuous(breaks=c(1000, 2000, 3000, 4000, 5000), labels=c("1K", "2K", "3K", "4K", "5K")) +
  ggtitle('Total Population vs # Stores') +
  xlab('Total Population') + 
  ylab('# Jewelry Stores')

grid.arrange(g1, g2, ncol=2)

```

We did see that the larger Metro and Micro areas did have customers with higher **Total SalesLast 12 Mos** and as the **Urban Influence** moved towards rural the total sales significantly became lower. Additionally, we saw a significant correlation between the **Total Population** and the **Number of Stores** from out dataset.

# Build a Linear Model 

Using all the variables (except JBT Rating), we examined revelance of the variables in our dataset. The reason we exluded the JBT Rating is because we want to be able to make predictions for the new customers who do not have a Credit Rating, so we did not want this variable to play a role in our model.

```{r, echo=FALSE}

model <- lm(formula = CreditLimit ~ SalesCurrentYr + SalesLastYr + PlainBandSalesLast12Mo + DesignBandSalesLast12Mo + DiamondBandSalesLast12Mo + AlternativeMetalSalesLast12Mo + TotalSalesLast12Mo + BuyingGroupMember + NumberOfStoreLocations + AvgDaysOfPayCategory + AvgDaysOfPay + MaxDaysPastDue + MaxAmtPastDue + AvgAmtPastDue + ReturnedPaymentCount + MaxReturnedPaymentAmt + RuralUrbanContinuumCode + UrbanInfluenceCode + MetroIndicator + TotalPopulation + MedianEarnings + MedianRetailTradeEarnings + TotalHouseholds + MedianIncomeHouseholds + NumberOfJewelryStores + NumberOfJewelryStoresState + JewelryStoreSalesState, data = dataset_train)

summary(model)

```

After viewing the summary and looking at the significance of the coefficients we notice tha the coefficient with the highest P value is the intercept. Using **Backward Elimitaion**, we started going through the list of coefficients and removed the largest value coefficient one at a time and re-ran the model and the model summary.

### Remove the intercept

```{r, echo=FALSE}

model <- lm(formula = CreditLimit ~ 1 + SalesCurrentYr + SalesLastYr + PlainBandSalesLast12Mo + DesignBandSalesLast12Mo + DiamondBandSalesLast12Mo + AlternativeMetalSalesLast12Mo + TotalSalesLast12Mo + BuyingGroupMember + NumberOfStoreLocations + AvgDaysOfPayCategory + AvgDaysOfPay + MaxDaysPastDue + MaxAmtPastDue + AvgAmtPastDue + ReturnedPaymentCount + MaxReturnedPaymentAmt + RuralUrbanContinuumCode + UrbanInfluenceCode + MetroIndicator + TotalPopulation + MedianEarnings + MedianRetailTradeEarnings + TotalHouseholds + MedianIncomeHouseholds + NumberOfJewelryStores + NumberOfJewelryStoresState + JewelryStoreSalesState - 1, data = dataset_train)

summary(model)

```

### Backward Elimitaion to find the significant coefficients

After removing the coefficient the $R^2$ value went up significantly. Next coefficient in the list was the **Average Days of Pay Category** and even though the P values for the categorical coefficients were high/highest, removing this variable actually reduced the $R^2$ value of the model. Looking at our earlier graphs, we thought that there is some correlation between the Average Days of Pay Categories of 0-10 Days, 10-30 Days and 30-60 Days vs the Credit Limit so we have decided to keep this variable and remove the next lowest P value coefficient.

We went through the iteration of removing coefficients until we could no longer reduce the $R^2 Adjusted$ value.

```{r, echo=FALSE}
RSqrPerformance <- data.frame(
  Iterations = 1:22,
  Action = c('All Variables', 'Remove intercept', 'Remove AvgDaysOfPayCategory', 'Add AvgDaysOfPayCategory', 'Remove TotalHouseholds', 'Removed TotalPopulation', 'Remove MaxAmtPastDue', 'Remove AlternativeMetalSalesLast12Mo', 'Remove TotalSalesLast12Mo', 'Remove UrbanInfluenceCode', 'Remove MaxDaysPastDue', 'Remove DiamondBandSalesLast12Mo', 'Remove MaxReturnedPaymentAmt', 'Remove AvgDaysOfPay', 'Remove NumberOfJewelryStoresState', 'Remove JewelryStoreSalesState', 'Remove AvgAmtPastDue', 'Remove MedianRetailTradeEarnings', 'Remove PlainBandSalesLast12Mo', 'Remove NumberOfJewelryStores', 'Remove BuyingGroupMember', 'Remove ReturnedPaymentCount'),
  RSqrAdjValues = c(0.1201, 0.4704, 0.4455, 0.4704, 0.4708, 0.4713, 0.4717, 0.472, 0.4724, 0.4728, 0.4731, 0.4735, 0.4738, 0.474, 0.4743, 0.4746, 0.4749, 0.475, 0.4751, 0.4774, 0.4776, 0.4774)
)

print(RSqrPerformance)
```

Our final linear model became the following after our **Backward Elimitaion** process:

```{r}

model <- lm(formula = CreditLimit ~ SalesCurrentYr + SalesLastYr + DesignBandSalesLast12Mo + NumberOfStoreLocations + AvgDaysOfPayCategory + ReturnedPaymentCount + RuralUrbanContinuumCode + MetroIndicator + MedianEarnings + MedianIncomeHouseholds - 1, data = dataset_train)

summary(model)

```


# Build a linear model #2.a

Using the same relevant variables which we have used in our decision tree, we decided to see if we can build a linear model and compare it to the one we came up with after our Backward Elimination process.

```{r, echo=FALSE}

model <- lm(formula = CreditLimit ~ DesignBandSalesLast12Mo + AvgDaysOfPay + SalesLastYr + TotalSalesLast12Mo + AlternativeMetalSalesLast12Mo + MedianIncomeHouseholds + SalesCurrentYr + PlainBandSalesLast12Mo + MedianEarnings + RuralUrbanContinuumCode, data = dataset_train)

summary(model)

```

The $R^2 Adjusted$ value for this model was significantly lower than the model we came up with earlier.

# Build a linear model #2.b

We also wanted to examine if we could build a better linear model using non-sales variables

```{r, echo=FALSE}

model <- lm(formula = CreditLimit ~ RuralUrbanContinuumCode + MetroIndicator + MedianEarnings + MedianIncomeHouseholds + NumberOfJewelryStores - 1, data = dataset_train)

summary(model)

```

This one was significantly better than the one we came up with using the variables from the Decision Tree model and our original **Naive** model, but it wasn't better than the one we developed using the Backward Elimination.

# Build a linear models using different "family" parameters

```{r, echo=FALSE}

model <- glm(CreditLimit ~ SalesCurrentYr + SalesLastYr + DesignBandSalesLast12Mo + NumberOfStoreLocations + AvgDaysOfPayCategory + ReturnedPaymentCount + RuralUrbanContinuumCode + MetroIndicator + MedianEarnings + MedianIncomeHouseholds - 1, family = gaussian, data=dataset_train)

summary(model)

```

```{r, echo=FALSE}

predictions <- predict(model, dataset_train)

summary(predictions)

```





