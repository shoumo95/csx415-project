---
title: "Model Performance - linear"
author:
  - name: Soumyendu Sarkar
  - name: Hakan Egeli
date: 'April 29, 2018'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r setup, include=FALSE}
# load the project. This will autoload the data and also create training and test datasets
library('ProjectTemplate')
load.project()
```

#install.packages("reticulate")
#devtools::install_github("rstudio/keras")
#library(keras)
#install_keras()
#install.packages("keras")
#keras::install_keras()


```{r, echo=FALSE, include=FALSE}

library(caret)

# require(gridExtra)

# require(reticulate)
# require(keras)

```



THIS IS UNFINISHED WORK IN PROGRESS - PLEASE DO NOT EVALUATE

THIS IS JUST SAVED HERE SO THAT MULTIPLE GITHUB ACCOUNTS CAN ACCESS

---



```{r, echo=FALSE, include = FALSE}

library(keras)

dataset_train_nn <- dataset_train
dataset_test_nn <- dataset_test

dataset_train_nn <- subset(dataset_train_nn, SalesLastYr >= 0)
dataset_train_nn <- subset(dataset_train_nn, SalesLastYr < 80000)

dataset_train_nn <- subset(dataset_train_nn, SalesCurrentYr >= 0)
dataset_train_nn <- subset(dataset_train_nn, SalesCurrentYr < 80000)

dataset_test_nn <- subset(dataset_test_nn, SalesLastYr >= 0)
dataset_test_nn <- subset(dataset_test_nn, SalesLastYr < 80000)

dataset_test_nn <- subset(dataset_test_nn, SalesCurrentYr >= 0)
dataset_test_nn <- subset(dataset_test_nn, SalesCurrentYr < 80000)

#levels(dataset_train_nn$CreditLimitCategory) <- make.names(levels(factor(dataset_train_nn$CreditLimit)))
#levels(dataset_test_nn$CreditLimitCategory) <- make.names(levels(factor(dataset_test_nn$CreditLimit)))

#dataset_train$CreditLimitCat <- (dataset_train$CreditLimit)
#dataset_test$CreditLimitCat <- (dataset_test$CreditLimit)

dataset_train_nn$CreditLimitCat <- plyr::mapvalues(dataset_train_nn$CreditLimit, from = c(0, 500, 750, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 5000, 6000, 7000, 7500, 8000, 9000, 10000, 12000, 13000, 14000, 15000, 16000, 20000, 30000, 45000), to = c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22, 23, 24))

dataset_test_nn$CreditLimitCat <- plyr::mapvalues(dataset_test_nn$CreditLimit, from = c(0, 500, 750, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 5000, 6000, 7000, 7500, 8000, 9000, 10000, 12000, 13000, 14000, 15000, 16000, 20000, 30000, 45000), to = c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22, 23, 24))


filter_x_1 <- c("SalesCurrentYr", "SalesLastYr", "DesignBandSalesLast12Mo", "NumberOfStoreLocations", "ReturnedPaymentCount", "RuralUrbanContinuumCode", "MetroIndicator", "MedianEarnings", "MedianIncomeHouseholds", "TotalPopulation", "MedianRetailTradeEarnings", "NumberOfJewelryStoresState", "JewelryStoreSalesState")

filter_y_1 <- c("CreditLimitCat")

x_train_aux <- dataset_train_nn[filter_x_1]
y_train_aux <- dataset_train_nn[filter_y_1]

x_test_aux <- dataset_test_nn[filter_x_1]
y_test_aux <- dataset_test_nn[filter_y_1]

x_train_aux[, 1:3] = scale(x_train_aux[, 1:3])
x_train_aux[, 8:13] = scale(x_train_aux[, 8:13])

x_test_aux[, 1:3] = scale(x_test_aux[, 1:3])
x_test_aux[, 8:13] = scale(x_test_aux[, 8:13])

x_train <- matrix(unlist(x_train_aux), ncol = 13, byrow = TRUE)
x_test <- matrix(unlist(x_test_aux), ncol = 13, byrow = TRUE)

y_train <- matrix(unlist(y_train_aux), ncol = 1, byrow = TRUE)
y_test <- matrix(unlist(y_test_aux), ncol = 1, byrow = TRUE)

y_train <- to_categorical(y_train, 25)
y_test <- to_categorical(y_test, 25)



```






```{r, echo=FALSE, include = FALSE}

model <- keras_model_sequential() 
model %>% 
  layer_dense(units = 64, activation = 'relu', input_shape = ncol(x_train)) %>% 
  layer_dropout(rate = 0.2) %>% 
  layer_dense(units = 128, activation = 'relu') %>%
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = 128, activation = 'relu') %>%
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = 25, activation = 'softmax')

summary(model)


model %>% compile(
  loss = 'categorical_crossentropy',
  optimizer = optimizer_rmsprop(),
  metrics = c('accuracy')
)


# tensorboard("logs/run_a")

history <- model %>% fit(
  as.matrix(x_train), y_train, 
  epochs = 30, batch_size = 128, 
  verbose = 1,
#  callbacks = callback_tensorboard("logs/run_a"),
  validation_split = 0.2
)

#tensorboard(c("logs/run_a"))

model %>% evaluate(x_test, y_test)

y_hat <- (model %>% predict_classes(x_test))


plot(history)


# history_df <- as.data.frame(history)
# str(history_df)


#y_hat <- predict(model, x_test, type="class")

t <- table(y_hat, dataset_test_nn$CreditLimitCat)

#cm <- confusionMatrix(data=predictions, reference=dataset_test_nn$CreditLimitCategory)
#cm <- confusionMatrix(data=t)

#cm$table



```



```{r, echo=FALSE, include = FALSE}

dataset_train_nn$CreditLimitCategory <- factor(dataset_train_nn$CreditLimit)
dataset_test_nn$CreditLimitCategory <- factor(dataset_test_nn$CreditLimit)

dataset_train_nn <- subset(dataset_train_nn, SalesLastYr > 0)
dataset_train_nn <- subset(dataset_train_nn, SalesLastYr < 80000)

dataset_train_nn <- subset(dataset_train_nn, SalesCurrentYr > 0)
dataset_train_nn <- subset(dataset_train_nn, SalesCurrentYr < 80000)

dataset_test_nn <- subset(dataset_test_nn, SalesLastYr > 0)
dataset_test_nn <- subset(dataset_test_nn, SalesLastYr < 80000)

dataset_test_nn <- subset(dataset_test_nn, SalesCurrentYr > 0)
dataset_test_nn <- subset(dataset_test_nn, SalesCurrentYr < 80000)

levels(dataset_train_nn$CreditLimitCategory) <- make.names(levels(factor(dataset$CreditLimit)))
levels(dataset_test_nn$CreditLimitCategory) <- make.names(levels(factor(dataset$CreditLimit)))


filter_x_1 <- c("SalesCurrentYr", "SalesLastYr", "DesignBandSalesLast12Mo", "NumberOfStoreLocations", "ReturnedPaymentCount", "RuralUrbanContinuumCode", "MetroIndicator", "MedianEarnings", "MedianIncomeHouseholds")

filter_y_1 <- c("CreditLimit")

x_train_aux <- dataset_train_nn[filter_x_1]
y_train_aux <- dataset_train_nn[filter_y_1]

x_test_aux <- dataset_test_nn[filter_x_1]
y_test_aux <- dataset_test_nn[filter_y_1]

x_train_aux[, 1:3] = scale(x_train_aux[, 1:3])
x_train_aux[, 8:9] = scale(x_train_aux[, 8:9])

x_test_aux[, 1:3] = scale(x_test_aux[, 1:3])
x_test_aux[, 8:9] = scale(x_test_aux[, 8:9])

x_train <- matrix(unlist(x_train_aux), ncol = 9, byrow = TRUE)
x_test <- matrix(unlist(x_test_aux), ncol = 9, byrow = TRUE)

y_train <- matrix(unlist(y_train_aux), ncol = 1, byrow = TRUE)
y_test <- matrix(unlist(y_test_aux), ncol = 1, byrow = TRUE)


```




```{r, echo=FALSE, include = FALSE}


model <- keras_model_sequential() 
model %>% 
  layer_dense(units = 256, activation = 'relu', input_shape = ncol(x_train)) %>% 
  layer_dropout(rate = 0.2) %>% 
  layer_dense(units = 128, activation = 'relu') %>%
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = 10, activation = 'relu') %>%
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = 1) %>%

summary(model)


model %>% compile(
  loss = 'mean_squared_error',
  optimizer = optimizer_adam(),
  metrics = c('accuracy')
)


# tensorboard("logs/run_a")

history <- model %>% fit(
  as.matrix(x_train), y_train, 
  epochs = 30, batch_size = 128, 
  verbose = 1,
#  callbacks = callback_tensorboard("logs/run_a"),
  validation_split = 0.2
)

#tensorboard(c("logs/run_a"))

model %>% evaluate(x_test, y_test)

model %>% predict_classes(x_test)


plot(history)


history_df <- as.data.frame(history)
str(history_df)


```
