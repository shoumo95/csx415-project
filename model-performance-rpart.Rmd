---
title: "Model Performance - rpart"
author:
  - name: Hakan Egeli
  - name: Soumyendu Sarkar
date: 'April 24, 2018'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, echo=FALSE, include = FALSE}

# load the project. This will autoload the data and also create training and test datasets
library('ProjectTemplate')
load.project()

```

```{r, echo=FALSE, include=FALSE}

library(rpart)
library(rattle)
library(caret)

require(gridExtra)

```

# Decision Tree Model

Similart to building our intial linear model, we have examined the relevance of all the dependent variables. We identified the most relevant variables so that we can build our initial decision tree model accordingly.

```{r, echo=FALSE}

model <- rpart(CreditLimit ~ ., data = dataset_train)

```

```{r, echo=FALSE}

summary(model)

```

We also did a quick plot of our decision tree to visualize the model's output.

```{r, echo=FALSE}

fancyRpartPlot(model)

```

### What is the best cp to use?

Examining the model results, we wanted to determine the best cp value to use for our model to optimize it. To do that, we did a plot of the cp values and extracted the min cp value.

```{r, echo=FALSE}

plotcp(model)

```

```{r, echo=FALSE}

cat("Min cp value: ", model$cptable[which.min(model$cptable[,"xerror"]),"CP"])

```

### What are the most relevant variables?

```{r, echo=FALSE}

model$variable.importance

```

We took a close look at the most relevant variables and we have eliminated JBT Rating (as stated in our linear model, we want to predict credit limits for the customers that do not have a credit rating so we do not want this variable to influence our model), Credit Limit Lock, AvgDaysOfPay (Avg Days of Pay Category is already included), AvgAmtPastDue (we felt like this might not be a variable that we can obtain from a new customer), MaxDaysPastDue (again, this might not be a parameter that we can obtain from a potential new customer), and we ended up with the following:

```{r}

model <- rpart(CreditLimit ~ AvgDaysOfPayCategory + DesignBandSalesLast12Mo + SalesLastYr + TotalSalesLast12Mo + AlternativeMetalSalesLast12Mo + MedianIncomeHouseholds + SalesCurrentYr + PlainBandSalesLast12Mo + MedianEarnings + TotalHouseholds + TotalPopulation + NumberOfJewelryStores + RuralUrbanContinuumCode, data = dataset_train, control = rpart.control(cp = 0.0169))

```

```{r, echo=FALSE}

fancyRpartPlot(model)

```

```{r, echo=FALSE}

summary(model)

```

### Backward Elimitaion to find the significant coefficients

We perfomed a Backward Elimination; remove the least relevant (highest p) variables (MedianEarnings, TotalHouseholds, NumberOfJewelryStores, TotalPopulation, RuralUrbanContinuumCode) and rebuild the model.

```{r, echo=FALSE}

model <- rpart(CreditLimit ~ DesignBandSalesLast12Mo + AvgDaysOfPayCategory + SalesLastYr + TotalSalesLast12Mo + AlternativeMetalSalesLast12Mo + SalesCurrentYr + PlainBandSalesLast12Mo + MedianIncomeHouseholds, data = dataset_train, control = rpart.control(cp = 0.01))

```

```{r, echo=FALSE}

fancyRpartPlot(model)

```

```{r, echo=FALSE}

printcp(model)

```

```{r, echo=FALSE}

cat("Relative Error: 19489749 * 0.77040 = ", 19489749 * 0.77040)

```

### Credit Limit as a class

We wanted to see the impact on the decision tree model if we converted our Credit Limit values from numerical continious values to categorical values. So we set a new field and a copy of our training set and factorized the Credit Limit field.

```{r}
dataset_train_alt <- dataset_train

dataset_train_alt$CreditLimit <- factor(dataset_train_alt$CreditLimit) 

model <- rpart(CreditLimit ~ DesignBandSalesLast12Mo + AvgDaysOfPayCategory + SalesLastYr + TotalSalesLast12Mo + AlternativeMetalSalesLast12Mo + SalesCurrentYr + PlainBandSalesLast12Mo + MedianIncomeHouseholds, data = dataset_train_alt, control = rpart.control(cp = 0.002), method="class")

```

```{r, echo=FALSE, warning=FALSE}

fancyRpartPlot(model)

```

# Model Performance 

We built a confusion matrix to evaluate this model's performance

```{r}

predictions <- predict(model, dataset_train_alt, type = "class")

cm <- confusionMatrix(dataset_train_alt$CreditLimit, predictions)

```

```{r, echo=FALSE, warning=FALSE}

ggplot(data = data.frame(cm$table), aes(x=Prediction, y=Reference)) +
  geom_tile(aes(fill=Freq)) + 
  scale_fill_gradient(low = "white", high = "steelblue") +
  theme(axis.text.x=element_text(angle=90,hjust=1)) +
  xlab("Predictions") +
  ylab("Ground Truth (Observations)") +
  geom_text(aes(label = Freq), size = 2) +
  ggtitle("Decison Tree Plot of Confusion Matrix")

```

```{r, echo=FALSE}

print(cm$overall)

```

```{r, echo=FALSE}

print(cm$byClass)

```


```{r, echo=FALSE}

printcp(model)

```

```{r, echo=FALSE}

cat("Relative Error: 0.65111 * 0.67309 = ", 0.65111 * 0.67309)

```


Even though the model where we have converted the **Credit Limit** to a categorical value performed better than the one using continuous values, the Accuracy of the better model is very low. We will next try to take the variables actually used in this decision tree and try them on a linear model next to see if there can be any improvement made to the liner model based on what we learned from the decision tree model.

