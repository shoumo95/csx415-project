---
title: "Deep Learning Model Performance"
author:
  - name: Hakan Egeli
  - name: Soumyendu Sarkar
date: 'May 8, 2018'
knit: (function(inputFile, encoding) { 
      rmarkdown::render(inputFile,
                        encoding=encoding, 
                        output_file=file.path(dirname(inputFile), '../reports/', 'deep-learning-model-performance.html')) })
output: html_document
---

```{r, echo=FALSE}

#
# This mododule requires keras and Anaconda 3.x must be already installed on your system prior to running this code.
#
# after installing keras you must also run the following keras:: command as well!
#
# install.packages("keras")
# keras::install_keras()
#
require("keras")

```

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, root.dir = "..")
```


```{r, echo=FALSE, include = FALSE}

# ProjectTemplate will autoload the data and also create training and test datasets

cwd <- getwd()
setwd("..")

library('ProjectTemplate')
load.project()

setwd(cwd)

```


```{r, echo=FALSE, warning=FALSE, message=FALSE}
require(reticulate)

library(Hmisc)
library(caret)

```


---



```{r, echo=FALSE, include = FALSE}

library(keras)
library(tidyr)
library(ggplot2)

dataset_train_nn <- dataset_train
dataset_test_nn <- dataset_test

dataset_train_nn <- subset(dataset_train_nn, SalesLastYr >= 0)
dataset_train_nn <- subset(dataset_train_nn, SalesLastYr < 80000)

dataset_train_nn <- subset(dataset_train_nn, SalesCurrentYr >= 0)
dataset_train_nn <- subset(dataset_train_nn, SalesCurrentYr < 80000)

dataset_test_nn <- subset(dataset_test_nn, SalesLastYr >= 0)
dataset_test_nn <- subset(dataset_test_nn, SalesLastYr < 80000)

dataset_test_nn <- subset(dataset_test_nn, SalesCurrentYr >= 0)
dataset_test_nn <- subset(dataset_test_nn, SalesCurrentYr < 80000)

#factor(dataset_train_nn$CreditLimit)

levels(factor(dataset_train_nn$CreditLimit))
levels(factor(dataset_test_nn$CreditLimit))

dataset_train_nn$AvgDaysOfPayCategoryNum <- as.numeric(factor(dataset_train_nn$AvgDaysOfPayCategory))
dataset_test_nn$AvgDaysOfPayCategoryNum <- as.numeric(factor(dataset_test_nn$AvgDaysOfPayCategory))


dataset_train_nn[c("AvgDaysOfPay")][is.na(dataset_train_nn[c("AvgDaysOfPay")])] <- 0
dataset_test_nn[c("AvgDaysOfPay")][is.na(dataset_test_nn[c("AvgDaysOfPay")])] <- 0
#dataset_train_nn <- subset(dataset_train_nn, AvgDaysOfPay < 90)
#dataset_test_nn <- subset(dataset_test_nn, AvgDaysOfPay < 90)



#w = table(dataset_train_nn$CreditLimit)
#w
#y <- subset(dataset_train_nn, AvgDaysOfPay == NA)
#y


#j = table(dataset_test_nn$CreditLimit)
#j

dataset_train_nn<-dataset_train_nn[(dataset_train_nn$CreditLimit==0 | dataset_train_nn$CreditLimit==1000 | dataset_train_nn$CreditLimit==2000 | dataset_train_nn$CreditLimit==3000 | dataset_train_nn$CreditLimit==5000),]

dataset_test_nn<-dataset_test_nn[(dataset_test_nn$CreditLimit==0 | dataset_test_nn$CreditLimit==1000 | dataset_test_nn$CreditLimit==2000 | dataset_test_nn$CreditLimit==3000 | dataset_test_nn$CreditLimit==5000),]


dataset_train_nn$CreditLimitCat <- plyr::mapvalues(dataset_train_nn$CreditLimit, from = c(0, 1000, 2000, 3000, 5000), to = c(0,1,2,3,4))

dataset_test_nn$CreditLimitCat <- plyr::mapvalues(dataset_test_nn$CreditLimit, from = c(0, 1000, 2000, 3000, 5000), to = c(0,1,2,3,4))

dataset_train_nn$JBTRating <- as.numeric(factor(dataset_train_nn$JBTRating))
dataset_test_nn$JBTRating <- as.numeric(factor(dataset_test_nn$JBTRating))




filter_x_1 <- c("CreditLimitLocked", "JBTRating", "SalesCurrentYr", "SalesLastYr", "PlainBandSalesLast12Mo", "DesignBandSalesLast12Mo", "DiamondBandSalesLast12Mo", "AlternativeMetalSalesLast12Mo", "TotalSalesLast12Mo", "BuyingGroupMember", "NumberOfStoreLocations", "AvgDaysOfPay", "MaxDaysPastDue", "MaxAmtPastDue", "AvgAmtPastDue", "ReturnedPaymentCount", "MaxReturnedPaymentAmt", "RuralUrbanContinuumCode", "UrbanInfluenceCode", "MetroIndicator", "TotalPopulation", "MedianEarnings", "MedianRetailTradeEarnings", "TotalHouseholds", "MedianIncomeHouseholds", "NumberOfJewelryStores", "NumberOfJewelryStoresState", "JewelryStoreSalesState")




filter_x_2 <- c("JBTRating", "CreditLimitLocked", "SalesCurrentYr", "SalesLastYr", "DesignBandSalesLast12Mo", "NumberOfStoreLocations", "ReturnedPaymentCount", "RuralUrbanContinuumCode", "MetroIndicator", "MedianEarnings", "MedianIncomeHouseholds")

filter_x_3 <- c("JBTRating", "CreditLimitLocked", "SalesCurrentYr", "SalesLastYr", "DesignBandSalesLast12Mo", "NumberOfStoreLocations", "ReturnedPaymentCount", "RuralUrbanContinuumCode", "MetroIndicator", "MedianEarnings", "MedianIncomeHouseholds", "AvgDaysOfPayCategoryNum")

filter_x_4 <- c("CreditLimitCat", "JBTRating", "CreditLimitLocked", "SalesCurrentYr", "SalesLastYr", "DesignBandSalesLast12Mo", "NumberOfStoreLocations", "ReturnedPaymentCount", "RuralUrbanContinuumCode", "MetroIndicator", "MedianEarnings", "MedianIncomeHouseholds", "AvgDaysOfPayCategoryNum")

filter_x_5 <- c("SalesCurrentYr", "SalesLastYr", "DesignBandSalesLast12Mo", "NumberOfStoreLocations", "ReturnedPaymentCount", "MedianEarnings", "MedianIncomeHouseholds")



filter_y_1 <- c("CreditLimitCat")


pdata <- x_train_aux <- dataset_train_nn[filter_x_4]
pdata[, 1:13] = scale(pdata[, 1:13])


x_train_aux <- dataset_train_nn[filter_x_3]
y_train_aux <- dataset_train_nn[filter_y_1]

x_test_aux <- dataset_test_nn[filter_x_3]
y_test_aux <- dataset_test_nn[filter_y_1]

x_train_aux[, 1:12] = scale(x_train_aux[, 1:12])
x_test_aux[, 1:12] = scale(x_test_aux[, 1:12])


rescale<-function(m){
    return (m - min(m))/(max(m)-min(m))
}

#x_train_aux[, 1:28] = rescale(x_train_aux[, 1:28])
#x_test_aux[, 1:28] = rescale(x_test_aux[, 1:28])




#x_train_aux[, 3:9] = scale(x_train_aux[, 3:9])
#x_train_aux[, 12:15] = scale(x_train_aux[, 12:15])
#x_train_aux[, 21:28] = scale(x_train_aux[, 21:28])

#x_test_aux[, 3:9] = scale(x_test_aux[, 3:9])
#x_test_aux[, 12:15] = scale(x_test_aux[, 12:15])
#x_test_aux[, 21:28] = scale(x_test_aux[, 21:28])

#x_train <- as.matrix(sapply(x_train_aux, as.numeric)) 
#x_test <- as.matrix(sapply(x_test_aux, as.numeric)) 
#x_train <- unlist(x_train)
#x_test <- unlist(x_test)


doit <- function(x) {(x - min(x, na.rm=TRUE))/(max(x,na.rm=TRUE) - min(x, na.rm=TRUE))}
#x_train_aux <- as.data.frame(lapply(x_train_aux, doit))
#x_test_aux <- as.data.frame(lapply(x_test_aux, doit))
pdata <- as.data.frame(lapply(pdata, doit))


# plot(pdata[,-c(1,6)])


x_train <- as.matrix(as.data.frame(lapply(x_train_aux, as.numeric)))
x_test <- as.matrix(as.data.frame(lapply(x_test_aux, as.numeric)))

#normalized = (x_train[, 1:28]-min(x_train[, 1:28]))/(max(x_train[, 1:28])-min(x_train[, 1:28]))


x_train <- array_reshape(x_train, c(nrow(x_train), 12))
x_test <- array_reshape(x_test, c(nrow(x_test), 12))


y_train_aux_nn = y_train_aux
y_test_aux_nn = y_test_aux

y_train <- (y_train_aux_nn)
y_test <- (y_test_aux_nn)

#range01 <- function(x){(x-min(x))/(max(x)-min(x))}
#range01(x_train[, 1:28])
#range01(x_test[, 1:28])

#normalize(x_train[, 1:28])

y_train_aux_nn <- as.matrix(sapply(y_train_aux_nn, as.numeric)) 
y_test_aux_nn <- as.matrix(sapply(y_test_aux_nn, as.numeric)) 

y_train_v <- as.vector(y_train_aux_nn)
y_test_v <- as.vector(y_test_aux_nn)

y_test_nonc <- array_reshape(t(as.matrix(y_test)), c(nrow(y_test),1))


y_train <- to_categorical(unlist(y_train), 5)
y_test <- to_categorical(unlist(y_test), 5)

```





```{r, echo=FALSE, include = FALSE}

model <- keras_model_sequential() 
model %>% 
  layer_dense(units = 1024, activation = 'relu', input_shape = c(12)) %>% 
  layer_dropout(rate = 0.1) %>% 
  layer_dense(units = 1024, activation = 'relu') %>%
  layer_dropout(rate = 0.1) %>% 
  layer_dense(units = 256, activation = 'relu') %>%
  layer_dropout(rate = 0.1) %>% 
  layer_dense(units = 5, activation = 'softmax')


# summary(model)


# rprop = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.00001)

model %>% compile(
  loss = 'categorical_crossentropy',
  optimizer = optimizer_rmsprop(lr=0.0001, rho=0.9, decay=0.000001),
#  optimizer = optimizer_rmsprop(),
  metrics = c('accuracy')
)


# tensorboard("logs/run_a")

history <- model %>% fit(
  x_train, y_train, 
  epochs = 1000, batch_size = 512, 
  validation_split = 0.2
)


plot(history)

#tensorboard(c("logs/run_a"))


```


```{r, echo=FALSE}

model %>% evaluate(x_test, y_test)

y_test_hat <- model %>% predict_classes(x_test) 

# y_test_hat <- (model %>% predict_classes(x_test))
ytab <- table(y_test_v, y_test_hat)
mean(y_test_v == y_test_hat)
confusionMatrix(ytab)


```


