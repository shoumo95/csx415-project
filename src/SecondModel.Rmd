---
title: "Second Model"
author:
  - name: Hakan Egeli
  - name: Soumyendu Sarkar
date: 'April 21, 2018'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, echo=FALSE, include = FALSE}

# load the project. This will autoload the data and also create training and test datasets
library('ProjectTemplate')
load.project()

```

```{r, echo=FALSE, include=FALSE}

library(rpart)
library(rattle)
library(caret)

require(gridExtra)

```


## Perform some explortory data analysis.

- we looked at the dtree with all variables
- we choos the top variables
- we did iterated the dtree

- we took the same variables and reiterated out lm

- we took out the sales data to ceate an alternate model which does not depend on sales information

- Median Income and Median Income households which we obtained **census data** played a significant role

## Definitely plot (histogram) any response variables.
##Plot at your predictors.

d-tree plots

multiple univariable plots for lm

##Begin the analysis:

##For analysis/explanatory/exploratory projects start by

##For ML projects

##Build a linear model use lm for regression and/or glm( family=binomial. ... ) for classification

##Evaluate your linear model using your model evaluation RMarkdown document, if you are clever you can reuse the template and version it very quickly.

##Knit this to model-performance-linear.[html|pdf|md] where you are keeping your assets

##Make sure you know who to interpret a linear model! Let me know if we have to cover this.

##Build a tree model (rpart)

##plot the tree paying particular attention to the first few nodes, do they make sense?

##Evaluate your tree with you model evaluation RMarkdown document. Knit this to model-performance-rpart.[html|pdf|md]

##Has your model(s) met the model success criteria?


### Credit Limit vs Sales Numbers

```{r, echo=FALSE}
g1 <- ggplot() + 
  geom_point(aes(x = dataset$SalesLastYr, y = dataset$CreditLimit), color = 'blue') +
  xlab('Last Year\'s Sales') +
  ylab('Credit Limit') +
  scale_x_continuous(breaks=c(100000, 200000, 300000, 400000, 500000, 600000), labels=c("100K", "200K", "300K", "400K", "500K", "600K")) +
  scale_y_continuous(breaks=c(10000, 20000, 30000, 40000, 50000), labels=c("10K", "20K", "30K", "40K", "50K"))

g2 <- ggplot() + 
  geom_point(aes(x = dataset$SalesCurrentYr, y = dataset$CreditLimit), color = 'blue') +
  xlab('Current Year\'s Sales') + 
  ylab('Credit Limit') +
  scale_x_continuous(breaks=c(20000, 40000, 60000, 80000, 100000, 120000), labels=c("20K", "40K", "60K", "80K", "100K", "120K")) +
  scale_y_continuous(breaks=c(10000, 20000, 30000, 40000, 50000), labels=c("10K", "20K", "30K", "40K", "50K"))

g3 <- ggplot() + 
  geom_point(aes(x = dataset$TotalSalesLast12Mo, y = dataset$CreditLimit), color = 'blue') +
  xlab('Last 12 Mo\'s Sales') + 
  ylab('Credit Limit') +
  scale_x_continuous(breaks=c(100000, 200000, 300000, 400000, 500000, 600000), labels=c("100K", "200K", "300K", "400K", "500K", "600K")) +
  scale_y_continuous(breaks=c(10000, 20000, 30000, 40000, 50000), labels=c("10K", "20K", "30K", "40K", "50K"))

grid.arrange(g1, g2, g3, ncol=3)

```

### Correlation of 12 Months Sales and Major Product Category Sales

```{r, echo=FALSE}
g1 <- ggplot() + 
  geom_point(aes(x = dataset$PlainBandSalesLast12Mo, y = dataset$TotalSalesLast12Mo), color = 'blue') +
  xlab('Last 12 Mo\'s Plains $') +
  ylab('Last 12 Mo\'s $') +
  scale_x_continuous(limits=c(0, 100000), breaks=c(10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000), labels=c("10K", "20K", "30K", "40K", "50K", "60K", "70K", "80K", "90K", "100K")) +
  scale_y_continuous(breaks=c(100000, 200000, 300000, 400000), labels=c("100K", "200K", "300K", "400K"))

g2 <- ggplot() + 
  geom_point(aes(x = dataset$DesignBandSalesLast12Mo, y = dataset$TotalSalesLast12Mo), color = 'blue') +
  xlab('Last 12 Mo\'s Designs $') + 
  ylab('Last 12 Mo\'s $') +
  scale_x_continuous(limits=c(0, 100000), breaks=c(10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000), labels=c("10K", "20K", "30K", "40K", "50K", "60K", "70K", "80K", "90K", "100K")) +
  scale_y_continuous(breaks=c(100000, 200000, 300000, 400000), labels=c("100K", "200K", "300K", "400K"))

g3 <- ggplot() + 
  geom_point(aes(x = dataset$DiamondBandSalesLast12Mo, y = dataset$TotalSalesLast12Mo), color = 'blue') +
  xlab('Last 12 Mo\'s Diamonds $') + 
  ylab('Last 12 Mo\'s $') +
  scale_x_continuous(breaks=c(10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000), labels=c("10K", "20K", "30K", "40K", "50K", "60K", "70K", "80K", "90K", "100K")) +
  scale_y_continuous(breaks=c(100000, 200000, 300000, 400000), labels=c("100K", "200K", "300K", "400K"))

g4 <- ggplot() + 
  geom_point(aes(x = dataset$AlternativeMetalSalesLast12Mo, y = dataset$TotalSalesLast12Mo), color = 'blue') +
  xlab('Last 12 Mo\'s Alt Metal $') + 
  ylab('Last 12 Mo\'s $') +
  scale_x_continuous(breaks=c(10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000), labels=c("10K", "20K", "30K", "40K", "50K", "60K", "70K", "80K", "90K", "100K")) +
  scale_y_continuous(breaks=c(100000, 200000, 300000, 400000), labels=c("100K", "200K", "300K", "400K"))

grid.arrange(g1, g2, g3, g4, ncol=2)

```

### Distribution of Credit Limit

```{r, echo=FALSE}
ggplot() + 
  geom_histogram(aes(dataset$CreditLimit), bins = 40) +
  scale_x_continuous(breaks=c(5000, 10000, 15000, 20000, 30000, 40000, 50000), labels=c("5K", "10K", "15K", "20K", "30K", "40K", "50K")) +
  ggtitle('Distribution of Credit Limit') +
  xlab('Credit Limit') + 
  ylab('Distribution')
```


### Relationship Between Avg Days of Pay and Credit Limits

```{r, echo=FALSE}
ggplot(dataset, aes(x = AvgDaysOfPayCategory, y = CreditLimit, fill = AvgDaysOfPayCategory)) + 
  geom_boxplot(outlier.color = 'blue', outlier.shape = 1) +
  scale_y_log10() +
  stat_summary(fun.y = mean, geom = "point", shape = 1, size = 1, color = "white") +
  theme(legend.position = "") +
  ggtitle('Avg Days of Pay vs Credit Limit') +
  xlab('Avg Days of Pay') + 
  ylab('Credit Limit')
```

### Distribution of Credit Limit Among Avg Days of Pay

```{r, echo=FALSE}

ggplot(data = dataset, aes(x = CreditLimit)) + geom_histogram(binwidth = 2000) + facet_wrap(~AvgDaysOfPayCategory)

```

## Non-Sales Attributes and Possible Correlations

### Avg Days of Pay and Median Household Income 

```{r, echo=FALSE}
ggplot(dataset, aes(x = AvgDaysOfPayCategory, y = MedianIncomeHouseholds, color = CreditLimit)) + 
  geom_jitter() +
  stat_summary(fun.y = mean, geom = "point", shape = 1, size = 2, color = "red") +
  theme(legend.position = "") +
  ggtitle('Avg Days of Pay vs Credit Limit') +
  xlab('Avg Days of Pay') + 
  ylab('Median Income Households')
```

```{r, echo=FALSE}
g1 <- ggplot(dataset, aes(x = factor(UrbanInfluenceCode), y = dataset$TotalSalesLast12Mo, color = MetroIndicator)) + 
  geom_jitter() +
  scale_y_continuous(breaks=c(100000, 200000, 300000, 400000), labels=c("100K", "200K", "300K", "400K")) +
  stat_summary(fun.y = mean, geom = "point", shape = 1, size = 1, color = "white") +
  theme(legend.position = "") +
  ggtitle('12 Mo Sales Over Urban Influence') +
  xlab('Urban Influence Code') + 
  ylab('Total $ Last 12 Mo')

g2 <- ggplot() + 
  geom_point(aes(x = dataset$TotalPopulation, y = dataset$NumberOfJewelryStores), color = 'blue') +
  scale_x_continuous(breaks=c(5000000, 10000000, 15000000, 20000000), labels=c("5M", "10M", "15M", "20M")) +
  scale_y_continuous(breaks=c(1000, 2000, 3000, 4000, 5000), labels=c("1K", "2K", "3K", "4K", "5K")) +
  ggtitle('Corr Total Population vs # Stores') +
  xlab('Total Population') + 
  ylab('# Jewelry Stores')

grid.arrange(g1, g2, ncol=2)

```

# Decision Tree Model

## examine the relevance of all the dependent variables using a Decision Tree

```{r, echo=FALSE}

model <- rpart(CreditLimit ~ ., data = dataset_train)

```

```{r, echo=FALSE}

fancyRpartPlot(model)

```

```{r, echo=FALSE}

summary(model)

```


# what is the best cp to use?

```{r, echo=FALSE}

plotcp(model)

```

```{r, echo=FALSE}

model$cptable[which.min(model$cptable[,"xerror"]),"CP"]

```

# select the top relevant variables and revise our linear model

```{r, echo=FALSE}
model$variable.importance
#importance(model)

```

We have eliminated AvgDaysOfPay, AvgAmtPastDue, MaxDaysPastDue

```{r, echo=FALSE}

model <- rpart(CreditLimit ~ AvgDaysOfPayCategory + DesignBandSalesLast12Mo + SalesLastYr + TotalSalesLast12Mo + AlternativeMetalSalesLast12Mo + MedianIncomeHouseholds + SalesCurrentYr + PlainBandSalesLast12Mo + MedianEarnings + TotalHouseholds + TotalPopulation + NumberOfJewelryStores + RuralUrbanContinuumCode, data = dataset_train, control = rpart.control(cp = 0.0169))

```

```{r, echo=FALSE}

fancyRpartPlot(model)

```

```{r, echo=FALSE}

summary(model)

```

# Backward Elimination; remove the least relevant (highest p) variable and rebuild the model

SalesLastYr            TotalSalesLast12Mo                SalesCurrentYr       DesignBandSalesLast12Mo        PlainBandSalesLast12Mo AlternativeMetalSalesLast12Mo 
                           24                            21                            11                            11                             9                             8 
         AvgDaysOfPayCategory        MedianIncomeHouseholds

```{r, echo=FALSE}

model <- rpart(CreditLimit ~ DesignBandSalesLast12Mo + AvgDaysOfPayCategory + SalesLastYr + TotalSalesLast12Mo + AlternativeMetalSalesLast12Mo + SalesCurrentYr + PlainBandSalesLast12Mo + MedianIncomeHouseholds, data = dataset_train, control = rpart.control(cp = 0.01))

```

```{r, echo=FALSE}

fancyRpartPlot(model)

```

```{r, echo=FALSE}

printcp(model)

```

Relative error : 19489749 * 0.77040

# build a model based on sales related variables

```{r, echo=FALSE}
dataset_train_alt <- dataset_train

dataset_train_alt$CreditLimit <- factor(dataset_train_alt$CreditLimit) 

model <- rpart(CreditLimit ~ DesignBandSalesLast12Mo + AvgDaysOfPayCategory + SalesLastYr + TotalSalesLast12Mo + AlternativeMetalSalesLast12Mo + SalesCurrentYr + PlainBandSalesLast12Mo, data = dataset_train_alt, control = rpart.control(cp = 0.002), method="class")

```

```{r, echo=FALSE}

fancyRpartPlot(model)

```


```{r, echo=FALSE}

predictions <- predict(model, dataset_train_alt, type = "class")

```

# build a confusion matrix

```{r, echo=FALSE}

cm <- confusionMatrix(dataset_train_alt$CreditLimit, predictions)

ggplot(data = data.frame(cm$table), aes(x=Prediction, y=Reference)) +
  geom_tile(aes(fill=Freq)) + 
  scale_fill_gradient(low = "white", high = "steelblue") +
  theme(axis.text.x=element_text(angle=90,hjust=1)) +
  xlab("Predictions") +
  ylab("Ground Truth (Observations)") +
  geom_text(aes(label = Freq), size = 2) +
  ggtitle("Decison Tree Plot of Confusion Matrix")

```

```{r, echo=FALSE}

print(cm)

```

```{r, echo=FALSE}

printcp(model)

```

Relative Error : 0.67309 * 0.62884


# build a linear model using the same relevant variables which we have initially used in our decision tree

```{r, echo=FALSE}

model <- lm(formula = CreditLimit ~ DesignBandSalesLast12Mo + AvgDaysOfPay + SalesLastYr + TotalSalesLast12Mo + AlternativeMetalSalesLast12Mo + MedianIncomeHouseholds + SalesCurrentYr + PlainBandSalesLast12Mo + MedianEarnings + RuralUrbanContinuumCode, data = dataset_train)

```


```{r, echo=FALSE}

summary(model)

```

# examine a variation of a linear model using non-sales variables

```{r, echo=FALSE}

model <- lm(formula = CreditLimit ~ AvgDaysOfPay + MedianIncomeHouseholds + SalesCurrentYr + MedianEarnings, data = dataset_train)

```


```{r, echo=FALSE}

summary(model)

```

# ??? (we were examining the impact of standartizing )

```{r, echo=FALSE}

dataset_train_alt <- dataset_train

#dataset_train_alt$CreditLimit <- factor(dataset_train_alt$CreditLimit) 

model <- glm(CreditLimit ~ DesignBandSalesLast12Mo + SalesLastYr + AlternativeMetalSalesLast12Mo + MedianIncomeHouseholds + SalesCurrentYr + PlainBandSalesLast12Mo, family = gaussian, data=dataset_train_alt)

```

```{r, echo=FALSE}

summary(model)

```

# linear models using different "family" parameters

```{r, echo=FALSE}

dataset_train_alt <- dataset_train

#dataset_train_alt$CreditLimit <- factor(dataset_train_alt$CreditLimit) 

model <- glm(CreditLimit ~ 0 + DesignBandSalesLast12Mo + AlternativeMetalSalesLast12Mo + SalesCurrentYr + PlainBandSalesLast12Mo + DiamondBandSalesLast12Mo, family = gaussian, data=dataset_train_alt)


```


```{r, echo=FALSE}

summary(model)

```



```{r, echo=FALSE}

dataset_train_alt <- dataset_train

#dataset_train_alt$CreditLimit <- factor(dataset_train_alt$CreditLimit) 

model <- glm(CreditLimit ~ 0 + RuralUrbanContinuumCode + UrbanInfluenceCode + TotalPopulation + MedianIncomeHouseholds + NumberOfJewelryStores + NumberOfJewelryStoresState + JewelryStoreSalesState, family = gaussian, data=dataset_train_alt)


```


```{r, echo=FALSE}

summary(model)

```

```{r, echo=FALSE}

dataset_train_alt <- dataset_train

#dataset_train_alt$CreditLimit <- factor(dataset_train_alt$CreditLimit) 

model <- glm(CreditLimit ~ 0 + RuralUrbanContinuumCode + UrbanInfluenceCode + TotalPopulation + MedianIncomeHouseholds + NumberOfJewelryStores + NumberOfJewelryStoresState + JewelryStoreSalesState, family = poisson, data=dataset_train_alt)


```


```{r, echo=FALSE}

summary(model)

```

# how do these models compare to each other and to the first "naive" model?

```{r, echo=FALSE}

predictions <- predict(model, dataset_train_alt)

summary(predictions)
#helper.RMSE(dataset_train_alt$CreditLimit[is.na(predictions)==FALSE], predictions[is.na(predictions)==FALSE])

helper.RSquared(dataset_train_alt$CreditLimit[is.na(predictions)==FALSE], predictions[is.na(predictions)==FALSE])

```






