---
title: "Model Performance"
author:
  - name: Hakan Egeli
  - name: Soumyendu Sarkar
date: 'May 8, 2018'
knit: (function(inputFile, encoding) { 
      rmarkdown::render(inputFile,
                        encoding=encoding, 
                        output_file=file.path(dirname(inputFile), '../reports/', 'model-performance.html')) })
output: html_document
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, root.dir = "..")
```


```{r, echo=FALSE, include = FALSE}

# ProjectTemplate will autoload the data and also create training and test datasets

cwd <- getwd()
setwd("..")

library('ProjectTemplate')
load.project()

setwd(cwd)

```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
require(ggplot2)
require(gridExtra)
require(caret)
require(randomForest)

# for multinom and nnet methods
library(nnet)

```

```{r, echo=FALSE, warning=FALSE, message=FALSE}

# optional parallelism to be used by caret's trainControl 
library(doParallel);

cl <- makeCluster(detectCores())
registerDoParallel(cl)

```

# Model After Backward Elimitaion Process


## Classification Models

```{r, echo=FALSE, warning=FALSE}

metric.create <- function(){
  setNames(data.frame(matrix(ncol = 4, nrow = 0)), c("Accuracy", "AccuracySD", "Kappa", "KappaSD"))
}

metric.append <- function(df, model, row_name){
  df_tmp <- metric.create()
  df_tmp <- bind_rows(df_tmp, c(Accuracy=mean(model$resample[["Accuracy"]]),
                                AccuracySD=sd(model$resample[["Accuracy"]]),
                                Kappa=mean(model$resample[["Kappa"]]),
                                KappaSD=sd(model$resample[["Kappa"]])))
  rownames(df_tmp) <- c(row_name)
  rbind(df, df_tmp)
}

df <- metric.create()

```

```{r, echo=FALSE, warning=FALSE}

control <- trainControl(method="repeatedcv", number=5, repeats=2, classProbs=TRUE, allowParallel=TRUE)

```

```{r, echo=FALSE, warning=FALSE}

model_naive <- train(CreditLimitCategory ~ SalesLastYr, data=dataset_train, method="rpart", metric="Accuracy", trControl=control)

df <- metric.append(df, model_naive, "naive")

```

```{r, echo=FALSE, warning=FALSE}

model_rpart <- train(CreditLimitCategory ~ JBTRating + CreditLimitLocked + SalesCurrentYr + SalesLastYr + DesignBandSalesLast12Mo + NumberOfStoreLocations + AvgDaysOfPayCategory + ReturnedPaymentCount + RuralUrbanContinuumCode + MetroIndicator + MedianEarnings + MedianIncomeHouseholds - 1, data=dataset_train, method="rpart", metric="Accuracy", trControl=control)

df <- metric.append(df, model_rpart, "rpart")

```

```{r, echo=FALSE, warning=FALSE}

model_rpart2 <- train(CreditLimitCategory ~ JBTRating + CreditLimitLocked + SalesCurrentYr + SalesLastYr + DesignBandSalesLast12Mo + NumberOfStoreLocations + AvgDaysOfPayCategory + ReturnedPaymentCount + RuralUrbanContinuumCode + MetroIndicator + MedianEarnings + MedianIncomeHouseholds - 1, data=dataset_train, method="rpart2", metric="Accuracy", trControl=control)

df <- metric.append(df, model_rpart2, "rpart2")

```

```{r, echo=FALSE, warning=FALSE, message=FALSE}

model_steplda <- train(CreditLimitCategory ~ JBTRating + CreditLimitLocked + SalesCurrentYr + SalesLastYr + DesignBandSalesLast12Mo + NumberOfStoreLocations + AvgDaysOfPayCategory + ReturnedPaymentCount + RuralUrbanContinuumCode + MetroIndicator + MedianEarnings + MedianIncomeHouseholds - 1, data=dataset_train, method="stepLDA", metric="Accuracy", trControl=control, trace=FALSE)

df <- metric.append(df, model_steplda, "steplda")

```

```{r, echo=FALSE, warning=FALSE}

model_svmLinear <- train(CreditLimitCategory ~ JBTRating + CreditLimitLocked + SalesCurrentYr + SalesLastYr + DesignBandSalesLast12Mo + NumberOfStoreLocations + AvgDaysOfPayCategory + ReturnedPaymentCount + RuralUrbanContinuumCode + MetroIndicator + MedianEarnings + MedianIncomeHouseholds - 1, data=dataset_train, method="svmLinear", metric="Accuracy", trControl=control)

df <- metric.append(df, model_svmLinear, "svmLinear")

```

```{r, echo=FALSE, warning=FALSE}

model_svmRad <- train(CreditLimitCategory ~ JBTRating + CreditLimitLocked + SalesCurrentYr + SalesLastYr + DesignBandSalesLast12Mo + NumberOfStoreLocations + AvgDaysOfPayCategory + ReturnedPaymentCount + RuralUrbanContinuumCode + MetroIndicator + MedianEarnings + MedianIncomeHouseholds - 1, data=dataset_train, method="svmRadial", metric="Accuracy", trControl=control)

df <- metric.append(df, model_svmRad, "svmRad")

```

```{r, echo=FALSE, warning=FALSE}

model_svmPoly <- train(CreditLimitCategory ~ JBTRating + CreditLimitLocked + SalesCurrentYr + SalesLastYr + DesignBandSalesLast12Mo + NumberOfStoreLocations + AvgDaysOfPayCategory + ReturnedPaymentCount + RuralUrbanContinuumCode + MetroIndicator + MedianEarnings + MedianIncomeHouseholds - 1, data=dataset_train, method="svmPoly", metric="Accuracy", trControl=control)

df <- metric.append(df, model_svmPoly, "svmPoly")

```

```{r, echo=FALSE, warning=FALSE}

model_rf <- train(CreditLimitCategory ~ JBTRating + CreditLimitLocked + SalesCurrentYr + SalesLastYr + DesignBandSalesLast12Mo + NumberOfStoreLocations + AvgDaysOfPayCategory + ReturnedPaymentCount + RuralUrbanContinuumCode + MetroIndicator + MedianEarnings + MedianIncomeHouseholds - 1, data=dataset_train, method="rf", metric="Accuracy", trControl=control, tuneGrid=data.frame(.mtry=19))

df <- metric.append(df, model_rf, "rf")

```

```{r, echo=FALSE, warning=FALSE}

model_multinom <- train(CreditLimitCategory ~ JBTRating + CreditLimitLocked + SalesCurrentYr + SalesLastYr + DesignBandSalesLast12Mo + NumberOfStoreLocations + AvgDaysOfPayCategory + ReturnedPaymentCount + RuralUrbanContinuumCode + MetroIndicator + MedianEarnings + MedianIncomeHouseholds - 1, data=dataset_train, method="multinom", metric="Accuracy", trControl=control, maxit=600, trace=FALSE)

df <- metric.append(df, model_multinom, "multi")

```

```{r, echo=FALSE, warning=FALSE}

model_avNNet <- train(CreditLimitCategory ~ JBTRating + CreditLimitLocked + SalesCurrentYr + SalesLastYr + DesignBandSalesLast12Mo + NumberOfStoreLocations + AvgDaysOfPayCategory + ReturnedPaymentCount + RuralUrbanContinuumCode + MetroIndicator + MedianEarnings + MedianIncomeHouseholds - 1, data=dataset_train, method="avNNet", metric="Accuracy", trControl=control, maxit=600, trace=FALSE)

df <- metric.append(df, model_avNNet, "avNNet")

```

```{r, echo=FALSE, warning=FALSE}

model_nnet <- train(CreditLimitCategory ~ JBTRating + CreditLimitLocked + SalesCurrentYr + SalesLastYr + DesignBandSalesLast12Mo + NumberOfStoreLocations + AvgDaysOfPayCategory + ReturnedPaymentCount + RuralUrbanContinuumCode + MetroIndicator + MedianEarnings + MedianIncomeHouseholds - 1, data=dataset_train, method="nnet", trControl=control, tuneGrid=data.frame(.size=20, .decay=1.0e-1), rang=0.1, maxit=10000, trace=FALSE)

df <- metric.append(df, model_nnet, "nnet")

```

To improve our initial Naive model we have built several more models for our classification problem using:

* Decision Tree (**rpart** and **raprt2**),
* Linear Discriminant Analysis with Stepwise Feature Selection (**stepLDA**),
* Neural Networks Using Model Averaging (**avNNet**),
* Multinomial Regression Model via Neural Networks (**multinom**),
* Random Forest (**rf**),
* Single-hidden-layer Neural Network (**nnet**),
* Support Vector Machines with Linear Kernel (**svmLinear**)
* Support Vector Machines with Radial Basis Function Kernel (**svmRad**)
* Support Vector Machines with Polynomial Kernel (**svmPoly**)

and we have performed a repeated K-fold cross-validation totaling 10 folds for each model.


```{r, echo=FALSE, warning=FALSE}

# display the metric for Accuracy and Kappa values
df[with(df, order(-Accuracy)),]

```

```{r, echo=FALSE, warning=FALSE}
data <- data.frame(naive=model_naive$resample$Accuracy,
                   rpart=model_rpart$resample$Accuracy,
                   rpart2=model_rpart2$resample$Accuracy,
                   steplda=model_steplda$resample$Accuracy,
                   svmLinear=model_svmLinear$resample$Accuracy,
                   svmRad=model_svmRad$resample$Accuracy,
                   svmPoly=model_svmPoly$resample$Accuracy,
                   rf=model_rf$resample$Accuracy,
                   multinom=model_multinom$resample$Accuracy,
                   avNNet=model_avNNet$resample$Accuracy,
                   nnet=model_nnet$resample$Accuracy)
data <- gather(data, model, accuracy, naive:nnet)

ggplot(data, aes(x = model, y = accuracy, fill = model)) + 
  geom_boxplot(outlier.size = 0) +
  stat_summary(fun.y = mean, geom = "point", shape = 1, size = 1, color = "white") +
  theme(legend.position = "") +
  ggtitle('Accuracy Confidence Interval') +
  xlab('Model') + 
  ylab('Accuracy')

```

We looked at the Accuracy and Kappa model performance metrics and the confidence interval for each model and determined that the Random Forest model and the Multinomial Regression model were the top two performers. Then, we cheched the performance metics for these two top models against the test dataset that we have set aside (which as not used during the training) to re-evaluate their performance.

## Classification Test Accuracy for the Top Two Models

Random Rorest model against the test data:

```{r, warning=FALSE}

predictions <- predict(model_rf, newdata=dataset_test)
cm <- confusionMatrix(dataset_test$CreditLimitCategory, predictions)
cm$overall

```
```{r, echo=FALSE}

cm$byClass[,c("Sensitivity", "Specificity", "Precision", "Recall")]

```

```{r, echo=FALSE, warning=FALSE}

ggplot(data = data.frame(cm$table), aes(x=Prediction, y=Reference)) +
  geom_tile(aes(fill=Freq)) + 
  scale_fill_gradient(low = "white", high = "steelblue") +
  theme(axis.text.x=element_text(angle=90,hjust=1)) +
  xlab("Predictions") +
  ylab("Ground Truth (Observations)") +
  geom_text(aes(label = Freq), size = 2) +
  ggtitle("Random Forest Confusion Matrix")

```

Multinomial Regression model against the test data:

```{r, warning=FALSE}

predictions <- predict(model_nnet, newdata=dataset_test)
cm <- confusionMatrix(dataset_test$CreditLimitCategory, predictions)
cm$overall

```

```{r, echo=FALSE}

cm$byClass[,c("Sensitivity", "Specificity", "Precision", "Recall")]

```

```{r, echo=FALSE, warning=FALSE}

ggplot(data = data.frame(cm$table), aes(x=Prediction, y=Reference)) +
  geom_tile(aes(fill=Freq)) + 
  scale_fill_gradient(low = "white", high = "steelblue") +
  theme(axis.text.x=element_text(angle=90,hjust=1)) +
  xlab("Predictions") +
  ylab("Ground Truth (Observations)") +
  geom_text(aes(label = Freq), size = 2) +
  ggtitle("Multinomial Regression Confusion Matrix")

```

## Final Model

From the last two model tests, we have confirmed that the model built using the random forest was the one with the best accuracy and the best Kappa performance metrics.

We re-trainned the Random Forest model using the entire dataset in order to save this model and package it.

```{r}

model_rf <- train(CreditLimitCategory ~ JBTRating + CreditLimitLocked + SalesCurrentYr + SalesLastYr + DesignBandSalesLast12Mo + NumberOfStoreLocations + AvgDaysOfPayCategory + ReturnedPaymentCount + RuralUrbanContinuumCode + MetroIndicator + MedianEarnings + MedianIncomeHouseholds - 1, data=dataset, method="rf", metric="Accuracy", trControl=control, tuneGrid=data.frame(.mtry=19))

```

Final Accuracy and Kappa values and Standard Deviations

```{r, echo=FALSE, warning=FALSE}

model_rf$results

```


```{r, echo=FALSE, include=FALSE}

# save the model as a file to be used in the model package
#saveRDS(model_rf, "../data/final_model.rds")

# save the test data to be included in the model package
#save(dataset_test, file = "../data/creditlimittestdata.rda")

```

```{r, echo=FALSE}

stopCluster(cl)

```
